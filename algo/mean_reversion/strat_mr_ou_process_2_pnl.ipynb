{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17781b4e-ef54-429a-b7d9-ade32d73b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from collections import namedtuple\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from algo.sde.ornstein_uhlenbeck_optimisation import OptimiserOU\n",
    "from algo.sde.ornstein_uhlenbeck_parameters import HedgeParamsOU, ModelParamsOU\n",
    "from etl.yfinance_data import get_pairs_data\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0064565-b139-4480-8d48-8cf110444f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = \"1h\"\n",
    "# interval = \"1d\"\n",
    "interval_map = {\n",
    "    \"1m\": timedelta(minutes=60*24*7),\n",
    "    \"1h\": timedelta(hours=24*90),\n",
    "    \"1d\": timedelta(days=365*1),   \n",
    "}\n",
    "test_size_map = {\n",
    "    \"1m\": int(60*2),\n",
    "    \"1h\": int(24*7),  # Good - 1 week horizon.\n",
    "    \"1d\": 30,   \n",
    "}\n",
    "\n",
    "num_test = test_size_map[interval]\n",
    "\n",
    "# Let one unit of time be equivalent to one step in the data. TODO: later - clean data to rm. discontinuities (weekends etc.).\n",
    "dt = 1\n",
    "\n",
    "ticker1 = \"BZ=F\"\n",
    "ticker2 = \"CL=F\"\n",
    "\n",
    "today = date.today()\n",
    "end_date = today.strftime(\"%Y-%m-%d\")\n",
    "start_date = (today - interval_map[interval]).strftime(\"%Y-%m-%d\")\n",
    "df_full = get_pairs_data(ticker1, ticker2, start_date, end_date, interval)\n",
    "\n",
    "print(f\"\\nDates Requested: {start_date} to {end_date}\")\n",
    "print(f\"Dates Received: {df_full.index[0]} to {df_full.index[-1]}\\n\")\n",
    "\n",
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fefdf7-27fc-4b19-ad4e-3a019599b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"mode\"] = \"train\"\n",
    "df_full.loc[df_full.index[-num_test:], \"mode\"] = \"test\"\n",
    "\n",
    "# Assess linearity\n",
    "sns.scatterplot(data=df_full, x=\"S1\", y=\"S2\", hue=\"mode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1b531-2696-455a-9d4a-acaffe9687ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(df_full) - num_test\n",
    "\n",
    "df = df_full.head(num_train).copy()\n",
    "df_test = df_full.tail(num_test).copy()\n",
    "\n",
    "len(df), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e67d1-0701-4deb-b6c4-bb3c44264c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedging Parameters - training set\n",
    "optimiser_train = OptimiserOU(A=1.0, dt=dt)\n",
    "hp_train, candidates_train = optimiser_train.optimise(asset1=df[\"S1\"].to_numpy(), asset2=df[\"S2\"].to_numpy())\n",
    "\n",
    "# Hedging Parameters - test set\n",
    "optimiser_test = OptimiserOU(A=1.0, dt=dt)\n",
    "hp_test, candidates_test = optimiser_test.optimise(asset1=df_test[\"S1\"].to_numpy(), asset2=df_test[\"S2\"].to_numpy())\n",
    "\n",
    "# Hedging Parameters - full set\n",
    "optimiser_full = OptimiserOU(A=1.0, dt=dt)\n",
    "hp_full, candidates_full = optimiser_full.optimise(asset1=df_full[\"S1\"].to_numpy(), asset2=df_full[\"S2\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633facac-24b3-4e5b-bde1-29a977ec321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = hp_train.alpha\n",
    "beta = hp_train.beta\n",
    "\n",
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45290548-04c2-4851-b3ea-f300e6194de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare long-run mean in train set vs. test set vs. full set (train+test).\n",
    "ymin = np.min([candidates_train.log_likelihoods, candidates_test.log_likelihoods, candidates_full.log_likelihoods])\n",
    "\n",
    "plt.plot(candidates_train.B_candidates, candidates_train.log_likelihoods, label=\"train\")\n",
    "plt.vlines(hp_train.B, ymin=ymin, ymax=hp_train.ou_params.log_likelihood, linestyle=\"dashed\")\n",
    "\n",
    "plt.plot(candidates_test.B_candidates, candidates_test.log_likelihoods, color=\"red\", label=\"test\")\n",
    "plt.vlines(hp_test.B, ymin=ymin, ymax=hp_test.ou_params.log_likelihood, color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "plt.plot(candidates_full.B_candidates, candidates_full.log_likelihoods, color=\"orange\", label=\"full\")\n",
    "plt.vlines(hp_full.B, ymin=ymin, ymax=hp_full.ou_params.log_likelihood, color=\"orange\", linestyle=\"dashed\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"B\")\n",
    "plt.ylabel(\"Log-Likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2d054-52de-45a9-b396-274a37122f93",
   "metadata": {},
   "source": [
    "# Cointegration Tests\n",
    "\n",
    "TODO: make `pre-trade analytics` pre-flight checks and sit out the market if failed for a period of time until passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cd298-8dd3-41d2-b34d-cfa15fca6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from algo.cointegration.augmented_dickey_fuller import print_adf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fe7b4-8888-4e8d-bae4-a38949f5dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity in the raw assets. We do not want this.\n",
    "p_value = 0.05\n",
    "\n",
    "adf_S1 = adfuller(df[\"S1\"], regression=\"ct\")\n",
    "adf_S2 = adfuller(df[\"S2\"], regression=\"ct\")\n",
    "\n",
    "_msg = f\"Stationarity detected in raw asset time series, at p-value = {p_value}\"\n",
    "assert adf_S1[1] > p_value, _msg\n",
    "assert adf_S2[1] > p_value, _msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702eb30-74fd-421e-971c-428d3a0e5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "df[\"spread\"] = alpha*df[\"S1\"] - beta*df[\"S2\"]\n",
    "\n",
    "# adf_spread = adfuller(df[\"spread\"], maxlag=1)\n",
    "adf_spread = adfuller(df[\"spread\"], regression=\"ct\")\n",
    "print_adf_results(adf_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d77fb4-b2e7-425b-8e75-807b46130fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set, under hedging parameters calibrated on the training set\n",
    "df_test[\"spread\"] = alpha*df_test[\"S1\"] - beta*df_test[\"S2\"]\n",
    "\n",
    "# adf_spread_test = adfuller(df_test[\"spread\"], maxlag=1)\n",
    "adf_spread_test = adfuller(df_test[\"spread\"], regression=\"ct\")\n",
    "print_adf_results(adf_spread_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e732c-3388-4dd6-8ec6-d9d5cf0cc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require stationarity in the constructed spread time series\n",
    "adf_spread[1] < p_value, adf_spread_test[1] < p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379e959-fc44-4ccb-9730-5b86c54f0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johansen Test\n",
    "critical_values = {\n",
    "    0: {0.9: 13.4294, 0.95: 15.4943, 0.99: 19.9349},  # Critical values for 0 cointegration relationships.\n",
    "    1: {0.9: 2.7055, 0.95: 3.8415, 0.99: 6.6349},     # Critical values for 1 cointegration relationship.\n",
    "}\n",
    "\n",
    "trace0_cv_95 = critical_values[0][0.95]\n",
    "trace1_cv_95 = critical_values[1][0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386343e-703b-4587-b18a-17f4cd01080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b1d96-859d-4d4b-a058-024212149c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = df[[\"S1\", \"S2\"]]\n",
    "\n",
    "# Vector Autoregressive Model\n",
    "var = VAR(df_prices.values)\n",
    "lags = var.select_order()\n",
    "k_ar_diff = lags.selected_orders[\"aic\"]\n",
    "\n",
    "cj = coint_johansen(df_prices, det_order=0, k_ar_diff=k_ar_diff)\n",
    "\n",
    "# lr1 := Trace Statistic\n",
    "trace0, trace1 = cj.lr1\n",
    "\n",
    "# Did we pass the Johansen Test? - Require: (True, True).\n",
    "trace0 > trace0_cv_95, trace1 > trace1_cv_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db93cb-bcd1-4c47-8706-44be19aef348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Engle-Granger two-step cointegration test. Test in both directions.\n",
    "coint_t_stat_1, p_value_1 = coint(df[\"S1\"], df[\"S2\"], trend=\"c\")[:2]\n",
    "coint_t_stat_2, p_value_2 = coint(df[\"S2\"], df[\"S1\"], trend=\"c\")[:2]\n",
    "\n",
    "# Did we pass the Engle-Granger Test? - Require: (True, True).\n",
    "p_value_1 < p_value, p_value_2 < p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87c056-565d-4809-86b2-c729759d62b8",
   "metadata": {},
   "source": [
    "# SDE - OU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d189640-2d81-4e42-998d-297f3ad2a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.sde.ornstein_uhlenbeck_optimisation import estimate_halflife_ou\n",
    "\n",
    "\n",
    "spread = df[\"spread\"]\n",
    "estimate_halflife_ou(spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edca1d-b9c2-498c-ae1b-0dc1279105ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against own OU simulation\n",
    "from algo.sde.ornstein_uhlenbeck import OrnsteinUhlenbeck\n",
    "\n",
    "\n",
    "x = df[\"spread\"].to_numpy()\n",
    "\n",
    "# Test the process by running through an OU Model.\n",
    "ou_params = hp_train.ou_params\n",
    "ou_model = OrnsteinUhlenbeck(X_0=x[0], theta=ou_params.theta, k=ou_params.mu, sigma=ou_params.sigma)\n",
    "ou_process_simulated = ou_model(num_samples=len(x))\n",
    "df[\"X_t-sim\"] = ou_process_simulated\n",
    "\n",
    "\n",
    "# Test against library simulation\n",
    "import sdepy\n",
    "\n",
    "ou_lib = sdepy.ornstein_uhlenbeck_process(x0=x[0], theta=ou_params.theta, k=ou_params.mu, sigma=ou_params.sigma)\n",
    "df[\"X_t-sdepy\"] = ou_lib(np.linspace(1, len(df), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e048ad-f817-4bf4-9a37-0565af9f237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498ee1c-76fd-4290-a0c9-d7a3415dbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "oou = OptimiserOU(A=1.0, dt=dt)\n",
    "ou_params_sim = oou.model_params_ou(ou_process_simulated)\n",
    "\n",
    "\n",
    "def sim_results(ou_params, ou_params_sim):\n",
    "    # Want these differences to be as small as possible\n",
    "    df_summary = pd.DataFrame(columns=[\"Real Data\", \"Sim\", \"% Diff\"])\n",
    "    df_summary[\"Real Data\"] = [ou_params.theta, ou_params.mu, ou_params.sigma, ou_params.log_likelihood]\n",
    "    df_summary[\"Sim\"] = [ou_params_sim.theta, ou_params_sim.mu, ou_params_sim.sigma, ou_params_sim.log_likelihood]\n",
    "    df_summary[\"% Diff\"] = 100.0 * (df_summary[\"Real Data\"] - df_summary[\"Sim\"]) / df_summary[\"Real Data\"]\n",
    "    df_summary.index = [\"theta\", \"mu\", \"sigma\", \"log_li\"]\n",
    "    \n",
    "    return df_summary\n",
    "\n",
    "\n",
    "df_summary = sim_results(ou_params, ou_params_sim)\n",
    "df_summary.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe587e-3f54-4337-84dc-3af599cdd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = df_full.index[0]\n",
    "xmax = df_full.index[-1]\n",
    "\n",
    "\n",
    "plt.plot(df.index, df[\"spread\"], color=\"royalblue\", label=\"X_t-train\")\n",
    "plt.plot(df_test.index, df_test[\"spread\"], color=\"orange\", label=\"X_t-test\")\n",
    "plt.hlines(hp_train.ou_params.theta, xmin=xmin, xmax=xmax, color=\"darkblue\", linestyle=\"dashed\", label=\"theta_train\")\n",
    "plt.hlines(hp_test.ou_params.theta, xmin=xmin, xmax=xmax, color=\"red\", linestyle=\"dashed\", label=\"theta_test\")\n",
    "plt.hlines(hp_full.ou_params.theta, xmin=xmin, xmax=xmax, color=\"darkorange\", linestyle=\"dashed\", label=\"theta_full\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Spread\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025f428-7fdc-4e86-9c61-eb48b51ca870",
   "metadata": {},
   "source": [
    "# Z-score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a6223-ca13-47f9-8255-6f836a0cf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x, mean, std_dev):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: \n",
    "        mean: E[x], or a lagged value thereof.\n",
    "        std_dev: sqrt(Var[x]), or a lagged value thereof.\n",
    "    \"\"\"\n",
    "    return (x - mean) / std_dev\n",
    "    \n",
    "\n",
    "def zscore_signals(df_in, z_entry_threshold, z_exit_threshold):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x:\n",
    "        z_entry_threshold: when to long the portfolio, i.e. enter market.\n",
    "        z_exit_threshold: when to short the portfolio, i.e. exit market.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Cast bools -> floats\n",
    "    df[\"long\"] = 1.0*(df[\"zscore\"] <= -z_entry_threshold)\n",
    "    df[\"short\"] = 1.0*(df[\"zscore\"] >= z_entry_threshold)\n",
    "    df[\"exit\"] = 1.0*(np.abs(df[\"zscore\"]) <= z_exit_threshold)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "z_entry_threshold = 1.0\n",
    "z_exit_threshold = 0.5\n",
    "\n",
    "# Calibrate using only training set.\n",
    "df[\"zscore\"] = zscore(x=df[\"spread\"], mean=df[\"spread\"].mean(), std_dev=df[\"spread\"].std())\n",
    "df = df.pipe(zscore_signals, z_entry_threshold=z_entry_threshold, z_exit_threshold=z_exit_threshold)\n",
    "\n",
    "# Test using the mean and std_dev of the training set.\n",
    "df_test[\"zscore\"] = zscore(x=df_test[\"spread\"], mean=df[\"spread\"].mean(), std_dev=df[\"spread\"].std())\n",
    "df_test = df_test.pipe(zscore_signals, z_entry_threshold=z_entry_threshold, z_exit_threshold=z_exit_threshold)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df.index, df[\"zscore\"])\n",
    "plt.plot(df_test.index, df_test[\"zscore\"])\n",
    "plt.hlines(\n",
    "    [z_entry_threshold, -z_entry_threshold, z_exit_threshold, -z_exit_threshold],\n",
    "    colors=[\"gold\", \"gold\", \"red\", \"red\"],\n",
    "    xmin=df.index[0],\n",
    "    xmax=df_test.index[-1],\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb39d52-f588-43e4-b047-6662fb94b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_positions(df_in):\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # Signals to demonstrate when to propagate positions forward:\n",
    "    # - Stay long if: Z_exit_threshold < Z < Z_entry_threshold\n",
    "    # - Stay short if: Z_entry_threshold < Z < Z_exit_threshold\n",
    "    df[\"long_market\"] = 0.0  # Must be float\n",
    "    df[\"short_market\"] = 0.0  # Must be float\n",
    "\n",
    "    # Track whether to be long or short while iterating through each timestep\n",
    "    long_market = 0.0  # Must be float\n",
    "    short_market = 0.0  # Must be float\n",
    "\n",
    "    # Calculate when to be in the market via holding a long or short position, and when to exit the market.\n",
    "    # Hard to vectorise: note how `long_market` and `short_market` values are carried over in each loop iteration.\n",
    "    long_markets = []\n",
    "    short_markets = []\n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "        if row[1][\"long\"] == 1.0:\n",
    "            long_market = 1            \n",
    "        if row[1][\"short\"] == 1.0:\n",
    "            short_market = 1\n",
    "        if row[1][\"exit\"] == 1.0:\n",
    "            long_market = 0\n",
    "            short_market = 0\n",
    "\n",
    "        # Assign 1/0 to long_market/short_market to indicate when to stay in a position\n",
    "        long_markets.append(long_market)\n",
    "        short_markets.append(short_market)\n",
    "\n",
    "    df[\"long_market\"] = long_markets \n",
    "    df[\"short_market\"] = short_markets\n",
    "    df[\"positions\"] = df[\"long_market\"] - df[\"short_market\"]\n",
    "\n",
    "    # Using _pos to distinguish portfolio from raw.\n",
    "    df[\"S1_pos\"] = -1.0 * df[\"S1\"] * df[\"positions\"]\n",
    "    df[\"S2_pos\"] = df[\"S2\"] * df[\"positions\"]\n",
    "    df[\"total\"] = df[\"S1_pos\"] + df[\"S2_pos\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = df.pipe(compute_positions)\n",
    "df_test = df_test.pipe(compute_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507bb27-9c6f-42c5-87d9-9170aaf98c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convention: `returns := simple returns, returns_cml := cumulative returns`\n",
    "\n",
    "# TODO: S1_pos, S2_pos - made distinction to preserve data. Careful to propagate.\n",
    "\n",
    "def compute_returns(df_in):\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # Calculate simple percentage returns\n",
    "    df[\"returns_pc\"] = df[\"total\"].pct_change()\n",
    "\n",
    "    df[\"returns_pc\"].fillna(0.0, inplace=True)\n",
    "    df[\"returns_pc\"].replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "    df[\"returns_pc\"].replace(-1.0, 0.0, inplace=True)\n",
    "\n",
    "    # Accumulate returns across each time period\n",
    "    df[\"returns_cml\"] = (1.0 + df[\"returns_pc\"]).cumprod()\n",
    "\n",
    "    # S1 and S2 correct here: comparing PF to buy-and-hold.\n",
    "    df[\"returns_cml_S1\"] = (df[\"S1\"].pct_change()+1.0).cumprod()\n",
    "    df[\"returns_cml_S2\"] = (df[\"S2\"].pct_change()+1.0).cumprod()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = df.pipe(compute_returns)\n",
    "df_test = df_test.pipe(compute_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c134b9-2f6b-4b58-af13-22f124376d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"returns_cml\", \"returns_cml_S1\", \"returns_cml_S2\"]].plot()\n",
    "plt.title(\"Train Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a13a4c-2158-4a4a-a1f3-64ef81866e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[\"returns_cml\", \"returns_cml_S1\", \"returns_cml_S2\"]].plot()\n",
    "plt.title(\"Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f71bab-ae89-4aff-9439-acc61f5f02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio_simple(df, colname=\"returns_pc\"):\n",
    "    sharpe = df[colname].mean() / df[colname].std()\n",
    "    return sharpe\n",
    "    \n",
    "# sharpe_ratio = sharpe_ratio_simple(df)\n",
    "# sharpe_ratio_test = sharpe_ratio_simp(df_test)\n",
    "\n",
    "\n",
    "def sharpe_ratio_log(df, colname=\"total\"):\n",
    "    # Log returns are additive - better choice when doing *sqrt(252)\n",
    "    log_returns = np.log(df[colname]/df[colname].shift())\n",
    "    log_returns.fillna(0.0, inplace=True)\n",
    "    log_returns.replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "\n",
    "    sharpe = log_returns.mean()/log_returns.std()\n",
    "    return sharpe\n",
    "\n",
    "\n",
    "sharpe_ratio = sharpe_ratio_log(df)\n",
    "sharpe_ratio_test = sharpe_ratio_log(df_test)\n",
    "\n",
    "\n",
    "# Annualise: data is hourly. Futures: 23 hours in a trading day, 252 trading days in a year.\n",
    "# Portfolio returns are a BM -> volatility scales with sqrt(time).\n",
    "sharpe_ratio_annual = sharpe_ratio*np.sqrt(23*252)\n",
    "sharpe_ratio_annual_test = sharpe_ratio_test*np.sqrt(23*252)\n",
    "\n",
    "print(f\"Sharpe Annual Train Set = {sharpe_ratio_annual}\")\n",
    "print(f\"Sharpe Annual Test  Set = {sharpe_ratio_annual_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad11bef-08cf-43b7-b561-c76cd1113ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
